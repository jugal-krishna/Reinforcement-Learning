{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugal-krishna/Reinforcement-Learning/blob/main/RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KR9QHuleJ9Bh",
        "outputId": "6b27c125-d30c-48f5-afb3-806987ac1fdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing MIT deep learning package... Done\n"
          ]
        }
      ],
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# Download and import the MIT 6.S191 package\n",
        "!printf \"Installing MIT deep learning package... \"\n",
        "!pip install --upgrade git+https://github.com/aamini/introtodeeplearning.git &> /dev/null\n",
        "!echo \"Done\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EvdePP-VyVWp"
      },
      "outputs": [],
      "source": [
        "#Install some dependencies for visualizing the agents\n",
        "!apt-get install -y xvfb python-opengl x11-utils &> /dev/null\n",
        "!pip install gym pyvirtualdisplay scikit-video ffio pyrender &> /dev/null\n",
        "!pip install tensorflow_probability==0.12.0 &> /dev/null\n",
        "import os\n",
        "os.environ['PYOPENGL_PLATFORM'] = 'egl'\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib, cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import base64, io, os, time, gym\n",
        "import IPython, functools\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import mitdeeplearning as mdl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Vista Simulator\n",
        "\n",
        "!pip install --upgrade git+https://github.com/vista-simulator/vista-6s191.git"
      ],
      "metadata": {
        "id": "WKWcagMpRLIB",
        "outputId": "f5b274b5-fb11-4ff2-f4e8-ec93257afddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/vista-simulator/vista-6s191.git\n",
            "  Cloning https://github.com/vista-simulator/vista-6s191.git to /tmp/pip-req-build-58g6c1s7\n",
            "  Running command git clone -q https://github.com/vista-simulator/vista-6s191.git /tmp/pip-req-build-58g6c1s7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vista\n",
        "from vista.utils import logging\n",
        "logging.setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "ByV6c5GKTgHq",
        "outputId": "75b125f9-bf04-45ad-bc25-c9fa107e7c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[93m2022-04-11 18:25:46,665::WARNING::[vista.entities.sensors.EventCamera.<module>] Fail to import module for event camera. Remember to do source <some-dir>/openeb/build/utils/scripts/setup_env.shCan ignore this if not using it\u001b[0;0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Access documentation for VISTA\n",
        "### Run ?vista.<[name of module or function]>\n",
        "?vista.Display "
      ],
      "metadata": {
        "id": "-RTw0OK4nTYi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "id": "JrTpTBJsJ9Bp",
        "outputId": "011f3bfa-271f-4142-e8f3-1f20f0ca6a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping data...\n",
            "Done downloading and unzipping data!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1382.4x460.8 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create environment from VISTA\n",
        "\n",
        "# Download and extract the data for vista (auto-skip if already downloaded)\n",
        "!wget -nc -q --show-progress https://www.dropbox.com/s/62pao4mipyzk3xu/vista_traces.zip\n",
        "print(\"Unzipping data...\")\n",
        "!unzip -o -q vista_traces.zip\n",
        "print(\"Done downloading and unzipping data!\")\n",
        "\n",
        "trace_root = \"./vista_traces\"\n",
        "trace_path = [\n",
        "    \"20210726-154641_lexus_devens_center\", \n",
        "    \"20210726-155941_lexus_devens_center_reverse\", \n",
        "    \"20210726-184624_lexus_devens_center\", \n",
        "    \"20210726-184956_lexus_devens_center_reverse\", \n",
        "]\n",
        "trace_path = [os.path.join(trace_root, p) for p in trace_path]\n",
        "\n",
        "# Create a virtual world with VISTA, the world is defined by a series of data traces\n",
        "world = vista.World(trace_path, trace_config={'road_width': 4})\n",
        "\n",
        "# Create a car in our virtual world. The car will be able to step and take different \n",
        "#   control actions. As the car moves, its sensors will simulate any changes it environment\n",
        "car = world.spawn_agent(\n",
        "    config={\n",
        "        'length': 5.,\n",
        "        'width': 2.,\n",
        "        'wheel_base': 2.78,\n",
        "        'steering_ratio': 14.7,\n",
        "        'lookahead_road': True\n",
        "    })\n",
        "\n",
        "# Create a camera on the car for synthesizing the sensor data that we can use to train with! \n",
        "camera = car.spawn_camera(config={'size': (200, 320)})\n",
        "\n",
        "# Define a rendering display so we can visualize the simulated car camera stream and also \n",
        "#   get see its physical location with respect to the road in its environment. \n",
        "display = vista.Display(world, display_config={\"gui_scale\": 2, \"vis_full_frame\": False})\n",
        "\n",
        "# Define a simple helper function that allows us to reset VISTA and the rendering display\n",
        "def vista_reset():\n",
        "    world.reset()\n",
        "    display.reset()\n",
        "vista_reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZjFecj3WJ9Bp"
      },
      "outputs": [],
      "source": [
        "# First we define a step function, to allow our virtual agent to step \n",
        "# with a given control command through the environment \n",
        "# agent can act with a desired curvature (turning radius, like steering angle)\n",
        "# and desired speed. if either is not provided then this step function will \n",
        "# use whatever the human executed at that time in the real data.\n",
        "\n",
        "def vista_step(curvature=None, speed=None):\n",
        "    # Arguments:\n",
        "    #   curvature: curvature to step with\n",
        "    #   speed: speed to step with\n",
        "    if curvature is None: \n",
        "        curvature = car.trace.f_curvature(car.timestamp)\n",
        "    if speed is None: \n",
        "        speed = car.trace.f_speed(car.timestamp)\n",
        "    \n",
        "    car.step_dynamics(action=np.array([curvature, speed]), dt=1/15.)\n",
        "    car.step_sensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rp8G7eirJ9Bp"
      },
      "outputs": [],
      "source": [
        "import shutil, os, subprocess, cv2\n",
        "\n",
        "# Create a simple helper class that will assist us in storing videos of the render\n",
        "class VideoStream():\n",
        "    def __init__(self):\n",
        "        self.tmp = \"./tmp\"\n",
        "        if os.path.exists(self.tmp) and os.path.isdir(self.tmp):\n",
        "            shutil.rmtree(self.tmp)\n",
        "        os.mkdir(self.tmp)\n",
        "    def write(self, image, index):\n",
        "        cv2.imwrite(os.path.join(self.tmp, f\"{index:04}.png\"), image)\n",
        "    def save(self, fname):\n",
        "        cmd = f\"/usr/bin/ffmpeg -f image2 -i {self.tmp}/%04d.png -crf 0 -y {fname}\"\n",
        "        subprocess.call(cmd, shell=True)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "MlC5t0dyJ9Bq"
      },
      "outputs": [],
      "source": [
        "## Render and inspect a human trace ##\n",
        "\n",
        "vista_reset()\n",
        "stream = VideoStream()\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    vista_step()\n",
        "    \n",
        "    # Render and save the display\n",
        "    vis_img = display.render()\n",
        "    stream.write(vis_img[:, :, ::-1], index=i)\n",
        "    if car.done: \n",
        "        break\n",
        "\n",
        "print(\"Saving trajectory of human following...\")\n",
        "stream.save(\"human_follow.mp4\")      \n",
        "mdl.lab3.play_video(\"human_follow.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2_6U_VAFJ9Bq"
      },
      "outputs": [],
      "source": [
        "## Define terminal states and crashing conditions ##\n",
        "\n",
        "def check_out_of_lane(car):\n",
        "    distance_from_center = np.abs(car.relative_state.x)\n",
        "    road_width = car.trace.road_width \n",
        "    half_road_width = road_width / 2\n",
        "    return distance_from_center > half_road_width\n",
        "\n",
        "def check_exceed_max_rot(car):\n",
        "    maximal_rotation = np.pi / 10.\n",
        "    current_rotation = np.abs(car.relative_state.yaw)\n",
        "    return current_rotation > maximal_rotation\n",
        "\n",
        "def check_crash(car): \n",
        "    return check_out_of_lane(car) or check_exceed_max_rot(car) or car.done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIyI5MqwJ9Bq"
      },
      "outputs": [],
      "source": [
        "## Behavior with random control policy ##\n",
        "\n",
        "i = 0\n",
        "num_crashes = 5\n",
        "stream = VideoStream()\n",
        "\n",
        "for _ in range(num_crashes):\n",
        "    vista_reset()\n",
        "    \n",
        "    while not check_crash(car):\n",
        "\n",
        "        # Sample a random curvature (between +/- 1/3), keep speed constant\n",
        "        curvature = np.random.uniform(-1/3, 1/3)\n",
        "\n",
        "        # Step the simulated car with the same action\n",
        "        vista_step(curvature=curvature)\n",
        "\n",
        "        # Render and save the display\n",
        "        vis_img = display.render()\n",
        "        stream.write(vis_img[:, :, ::-1], index=i)\n",
        "        i += 1\n",
        "    \n",
        "    print(f\"Car crashed on step {i}\")\n",
        "    for _ in range(5):\n",
        "        stream.write(vis_img[:, :, ::-1], index=i)\n",
        "        i += 1\n",
        "\n",
        "print(\"Saving trajectory with random policy...\")\n",
        "stream.save(\"random_policy.mp4\")\n",
        "mdl.lab3.play_video(\"random_policy.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UxX6mk5J9Br"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Directly access the raw sensor observations of the simulated car\n",
        "vista_reset()\n",
        "full_obs = car.observations[camera.name]\n",
        "cv2_imshow(full_obs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ROIs ##\n",
        "import PIL\n",
        "# Crop a smaller region of interest (ROI). This is necessary because: \n",
        "#   1. The full observation will have distortions on the edge as the car deviates from the human\n",
        "#   2. A smaller image of the environment will be easier for our model to learn from\n",
        "region_of_interest = camera.camera_param.get_roi()\n",
        "i1, j1, i2, j2 = region_of_interest\n",
        "cropped_obs = full_obs[i1:i2, j1:j2]\n",
        "print(f'Initial size = {np.shape(cropped_obs)}')\n",
        "new_img = tf.image.resize(\n",
        "    cropped_obs,\n",
        "    [224,224])\n",
        "print(f'Final size = {tf.shape(new_img)}')\n",
        "cv2_imshow(cropped_obs)\n",
        "def tensor_to_image(tensor):\n",
        "    tensor = tensor\n",
        "    tensor = np.array(tensor, dtype=np.uint8)\n",
        "    if np.ndim(tensor)>3:\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return PIL.Image.fromarray(tensor)\n",
        "tensor_to_image(new_img)"
      ],
      "metadata": {
        "id": "KAH-5uxrbkng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "7GQY_UwSJ9Br"
      },
      "outputs": [],
      "source": [
        "## Data preprocessing functions ##\n",
        "\n",
        "# Takes a full observation as input and returns a preprocessed version\n",
        "def preprocess(full_obs):\n",
        "    # Extract ROI\n",
        "    i1, j1, i2, j2 = camera.camera_param.get_roi()\n",
        "    obs = full_obs[i1:i2, j1:j2]\n",
        "    obs = tf.image.resize(obs,[224,224])\n",
        "\n",
        "    return obs\n",
        "# grab the car's current observation (i.e., image view from its perspective), and then call the preprocess function on that observation\n",
        "def grab_and_preprocess_obs(car):\n",
        "    full_obs = car.observations[camera.name]\n",
        "    obs = preprocess(full_obs)\n",
        "    return obs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ceXYoMNcQegK",
        "outputId": "a9add4c4-5c5d-4bb2-d292-d59410a137c0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.Input(shape=(224,224,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZeBt7KQ4x4E",
        "outputId": "86836114-e142-441c-9bb5-f78365381d9b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_16')>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "f-pAQA7zJ9Br"
      },
      "outputs": [],
      "source": [
        "### Define the self-driving agent ###\n",
        "\n",
        "# Functionally define layers for convenience\n",
        "# All convolutional layers will have ReLu activation\n",
        "act = tf.keras.activations.swish\n",
        "Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='valid', activation=act)\n",
        "Flatten = tf.keras.layers.Flatten\n",
        "Dense = tf.keras.layers.Dense\n",
        "\n",
        "# Defines a CNN for the self-driving agent\n",
        "def create_driving_model():\n",
        "\n",
        "\n",
        "# Download pre-trained ResNet50\n",
        "  resnet = tf.keras.applications.ResNet50(weights='imagenet',\n",
        "                                 include_top=False, \n",
        "                                 input_tensor=tf.keras.Input(shape=(224,224,3)),\n",
        "                                 input_shape=(224,224,3))\n",
        "  for layer in resnet.layers[:170]:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  model = tf.keras.models.Sequential([\n",
        "      resnet,\n",
        "      Flatten(),\n",
        "\n",
        "      # Fully connected layer and output\n",
        "      Dense(units=128, activation=act),\n",
        "\n",
        "      Dense(units=2, activation=None) # TODO\n",
        "      # Dense('''TODO''')\n",
        "\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "driving_model = create_driving_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "-UWhFhToJ9Bs"
      },
      "outputs": [],
      "source": [
        "## The self-driving learning algorithm ##\n",
        "\n",
        "# hyperparameters\n",
        "max_curvature = 1/8. \n",
        "max_std = 0.1 \n",
        "\n",
        "def run_driving_model(image): \n",
        "  # takes an input image, and outputs a prediction of a continuous distribution of curvature\n",
        "    # Arguments:\n",
        "    #   image: an input image\n",
        "    # Returns:\n",
        "    #   pred_dist: predicted distribution of control actions \n",
        "    single_image_input = tf.rank(image) == 3  # missing 4th batch dimension\n",
        "    if single_image_input:\n",
        "        image = tf.expand_dims(image, axis=0)\n",
        "\n",
        "    distribution = driving_model(image) \n",
        "\n",
        "\n",
        "    mu, logsigma = tf.split(distribution, 2, axis=1)\n",
        "    mu = max_curvature * tf.tanh(mu) # conversion\n",
        "    sigma = max_std * tf.sigmoid(logsigma) + 0.005 # conversion\n",
        "    pred_dist = tfp.distributions.Normal(mu, sigma) \n",
        "\n",
        "    return pred_dist\n",
        "\n",
        "\n",
        "def compute_driving_loss(dist, actions, rewards):\n",
        "  # computes the loss for a prediction that is in the form of a continuous Normal distribution\n",
        "    # Arguments:\n",
        "    #   logits: network's predictions for actions to take\n",
        "    #   actions: the actions the agent took in an episode\n",
        "    #   rewards: the rewards the agent received in an episode\n",
        "    # Returns:\n",
        "    #   loss\n",
        "\n",
        "    neg_logprob = -1 * dist.log_prob(actions)\n",
        "\n",
        "    loss = tf.reduce_mean( neg_logprob * rewards ) \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Reward function ###\n",
        "\n",
        "# Helper function that normalizes an np.array x\n",
        "def normalize(x):\n",
        "    x -= np.mean(x)\n",
        "    x /= np.std(x)\n",
        "    return x.astype(np.float32)\n",
        "\n",
        "# Compute normalized, discounted, cumulative rewards (i.e., return)\n",
        "# Arguments:\n",
        "#   rewards: reward at timesteps in episode\n",
        "#   gamma: discounting factor\n",
        "# Returns:\n",
        "#   normalized discounted reward\n",
        "def discount_rewards(rewards, gamma=0.95): \n",
        "    discounted_rewards = np.zeros_like(rewards)\n",
        "    R = 0\n",
        "    for t in reversed(range(0, len(rewards))):\n",
        "        # update the total discounted reward\n",
        "        R = R * gamma + rewards[t]\n",
        "        discounted_rewards[t] = R\n",
        "      \n",
        "    return normalize(discounted_rewards)"
      ],
      "metadata": {
        "id": "8_fNrZPAM470"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Memory:\n",
        "    def __init__(self): \n",
        "        self.clear()\n",
        "\n",
        "  # Resets/restarts the memory buffer\n",
        "    def clear(self): \n",
        "        self.observations = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "\n",
        "  # Add observations, actions, rewards to memory\n",
        "    def add_to_memory(self, new_observation, new_action, new_reward): \n",
        "        self.observations.append(new_observation)\n",
        "        \n",
        "        self.actions.append(new_action)\n",
        "\n",
        "        self.rewards.append(new_reward)\n",
        "    def __len__(self):\n",
        "        return len(self.actions)\n",
        "\n",
        "# Instantiate a single Memory buffer\n",
        "memory = Memory()"
      ],
      "metadata": {
        "id": "aWn8d6FxI1z1"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Training step (forward and backpropagation) ###\n",
        "\n",
        "def train_step(model, loss_function, optimizer, observations, actions, discounted_rewards, custom_fwd_fn=None):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward propagate through the agent network\n",
        "\n",
        "        if custom_fwd_fn is not None:\n",
        "            prediction = custom_fwd_fn(observations)\n",
        "        else: \n",
        "            prediction = model(observations)\n",
        "\n",
        "        loss = loss_function(prediction, actions, discounted_rewards)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    grads, _ = tf.clip_by_global_norm(grads, 2)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ],
      "metadata": {
        "id": "cMIMLYhCIoJe"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training parameters and initialization ##\n",
        "## Re-run this cell to restart training from scratch ##\n",
        "\n",
        "learning_rate = 5e-4\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# instantiate driving agent\n",
        "vista_reset()\n",
        "driving_model = create_driving_model()\n",
        "# NOTE: the variable driving_model will be used in run_driving_model execution\n",
        "\n",
        "# to track our progress\n",
        "smoothed_reward = mdl.util.LossHistory(smoothing_factor=0.9)\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Rewards')\n",
        "\n",
        "# instantiate Memory buffer\n",
        "memory = Memory()"
      ],
      "metadata": {
        "id": "uZGn94sJCtBb"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "G8GhVvZQJ9Bs"
      },
      "outputs": [],
      "source": [
        "## Driving training! Main training block. ##\n",
        "## Note: stopping and restarting this cell will pick up training where you\n",
        "#        left off. To restart training you need to rerun the cell above as \n",
        "#        well (to re-initialize the model and optimizer)\n",
        "\n",
        "max_batch_size = 500\n",
        "max_reward = float('-inf') # keep track of the maximum reward acheived during training\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "for i_episode in range(500):\n",
        "\n",
        "    plotter.plot(smoothed_reward.get())\n",
        "    # Restart the environment\n",
        "    vista_reset()\n",
        "    memory.clear()\n",
        "    observation = grab_and_preprocess_obs(car)\n",
        "\n",
        "    while True:\n",
        "\n",
        "        curvature_dist = run_driving_model(observation)\n",
        "        curvature_action = curvature_dist.sample()[0,0]\n",
        "        \n",
        "        # Step the simulated car with the same action\n",
        "        vista_step(curvature_action)\n",
        "        observation = grab_and_preprocess_obs(car)\n",
        "               \n",
        "        # Compute the reward for this iteration\n",
        "        reward = 100.0 if not check_crash(car) else 0.0\n",
        "        \n",
        "        # add to memory\n",
        "        memory.add_to_memory(observation, curvature_action, reward)\n",
        "        \n",
        "        # if the episode is over\n",
        "        if reward == 0.0:\n",
        "            # determine total reward and keep a record of this\n",
        "            total_reward = sum(memory.rewards)\n",
        "            smoothed_reward.append(total_reward)\n",
        "            \n",
        "            # execute training step - remember we don't know anything about how the \n",
        "            #   agent is doing until it has crashed! if the training step is too large \n",
        "            #   we need to sample a mini-batch for this step.\n",
        "            batch_size = min(len(memory), max_batch_size)\n",
        "            i = np.random.choice(len(memory), batch_size, replace=False)\n",
        "            train_step(driving_model, compute_driving_loss, optimizer, \n",
        "                               observations=np.array(memory.observations)[i],\n",
        "                               actions=np.array(memory.actions)[i],\n",
        "                               discounted_rewards = discount_rewards(memory.rewards)[i], \n",
        "                               custom_fwd_fn=run_driving_model)            \n",
        "            # reset the memory\n",
        "            memory.clear()\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "DzeswkSnJ9Bt"
      },
      "outputs": [],
      "source": [
        "## Evaluation block!##\n",
        "\n",
        "i_step = 0\n",
        "num_episodes = 5\n",
        "num_reset = 5\n",
        "stream = VideoStream()\n",
        "for i_episode in range(num_episodes):\n",
        "    \n",
        "    # Restart the environment\n",
        "    vista_reset()\n",
        "    observation = grab_and_preprocess_obs(car)\n",
        "    \n",
        "    print(\"rolling out in env\")\n",
        "    episode_step = 0\n",
        "    while not check_crash(car) and episode_step < 100:\n",
        "        # using our observation, choose an action and take it in the environment\n",
        "        curvature_dist = run_driving_model(observation)\n",
        "        curvature = curvature_dist.mean()[0,0]\n",
        "\n",
        "        # Step the simulated car with the same action\n",
        "        vista_step(curvature)\n",
        "        observation = grab_and_preprocess_obs(car)\n",
        "\n",
        "        vis_img = display.render()\n",
        "        stream.write(vis_img[:, :, ::-1], index=i_step)\n",
        "        i_step += 1\n",
        "        episode_step += 1\n",
        "        \n",
        "    for _ in range(num_reset):\n",
        "        stream.write(np.zeros_like(vis_img), index=i_step)\n",
        "        i_step += 1\n",
        "        \n",
        "print(f\"Average reward: {(i_step - (num_reset*num_episodes)) / num_episodes}\")\n",
        "\n",
        "print(\"Saving trajectory with trained policy...\")\n",
        "stream.save(\"trained_policy.mp4\")\n",
        "mdl.lab3.play_video(\"trained_policy.mp4\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}